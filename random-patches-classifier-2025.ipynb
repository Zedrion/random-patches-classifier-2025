{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dceaec-c6fd-44fc-b574-a48ada7f7152",
   "metadata": {},
   "source": [
    "## Random Patches definition\n",
    "\n",
    "Complete the code as required in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e98894-0251-42e8-9990-466ddb6a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "\n",
    "class RandomPatches(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=10, max_features=4, custom_voting=\"majority\", random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.custom_voting = custom_voting  # \"weighted_majority\" / \"probabilistic\" / default: \"majority\" \n",
    "        self.random_state = random_state\n",
    "        self.learners = []\n",
    "        self.subspaces = []\n",
    "        self.oob_scores = []\n",
    "        self.oob_sets_size = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        y = y.values if isinstance(y, pd.Series) else y\n",
    "        \n",
    "        # Ensure numpy arrays for consistency\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    " \n",
    "        # total number of instances and total number of features\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # for every member in the ensemble....\n",
    "        # Should select the patches (subsets of instances and features) and train a DecisionTreeClassifier()\n",
    "        # Also calculate the accuracy score for the oob and append it to oob_scores\n",
    "        for _ in range(self.n_estimators):\n",
    "\n",
    "            # Sample indices of instances and features\n",
    "            instance_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            feature_indices = np.random.choice(n_features, size=self.max_features, replace=False) \n",
    "            \n",
    "            # Generate patch for member in the ensemble as subset of X\n",
    "            X_patch = X[np.ix_(instance_indices, feature_indices)]\n",
    "            y_patch = y[instance_indices]\n",
    "            \n",
    "            # Train learner on the patch\n",
    "            learner = DecisionTreeClassifier(random_state=self.random_state)  \n",
    "            learner.fit(X_patch, y_patch)\n",
    "            \n",
    "            # Calculate OOB score for learner \n",
    "            oob_indices = np.delete(np.arange(n_samples), np.unique(instance_indices))  # Creates a new np array with all possible indices, then delete used indices from it \n",
    "            oob_score = 0.0 \n",
    "            oob_size = len(oob_indices)\n",
    "            if oob_size > 0:\n",
    "                X_oob = X[np.ix_(oob_indices, feature_indices)]\n",
    "                y_oob = y[oob_indices]\n",
    "                preds_oob = learner.predict(X_oob)\n",
    "                oob_score = np.mean(preds_oob == y_oob) * 100  # *100 to convert from decimal to percentage\n",
    "                    \n",
    "            self.learners.append(learner)\n",
    "            self.subspaces.append(feature_indices) # the features in that subspace\n",
    "            self.oob_scores.append(oob_score) # the accuracy on the oob set\n",
    "            self.oob_sets_size.append(oob_size) # number of elements in the oob\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        \n",
    "        predictions = np.array([learner.predict(X[:, subspace]) for learner, subspace in zip(self.learners, self.subspaces)])\n",
    "        pred_T = predictions.T  # Making each row a sample, for easier iteration through samples\n",
    "\n",
    "        # Weighted majority voting scheme\n",
    "        if self.custom_voting == \"weighted_majority\":\n",
    "            vote = [                                                                             #  A list of \n",
    "                max(                                                                             #  Max vote total weights\n",
    "                    np.unique(sample_preds),                                                     #  (from comparing the total weight for each unique prediction value in sample predictions)\n",
    "                    key=lambda label : sum(\n",
    "                                           oob                                                   #  with total weight being the sum of weights of all estimators that predicted said prediction value\n",
    "                                           for p, oob in zip(sample_preds, self.oob_scores) \n",
    "                                           if p == label)  \n",
    "                )\n",
    "                for sample_preds in pred_T]                                                      # For each sample in predictions (sample_preds is a list of all predictions from estimators for one sample)\n",
    "            \n",
    "        # Probabilistic voting scheme\n",
    "        elif self.custom_voting == \"probabilistic\":\n",
    "            vote = [                                                                             #  A list of \n",
    "                np.random.choice(sample_preds,                                                   #  Random choices from the list of sample predictions  \n",
    "                                 p=[oob / sum(self.oob_scores) for oob in self.oob_scores])   #  with estimators' normalized OOB scores (that sum up to 1) being probabilities \n",
    "                for sample_preds in pred_T]                                                      #  For each sample in predictions (sample_preds is a list of all predictions from estimators for one sample)\n",
    "            \n",
    "        # Majority voting scheme (default)\n",
    "        else: \n",
    "            vote = [                                                # A list of \n",
    "                max(                                                # Max vote counts (from comparing the counts of unique prediction value in sample predictions) \n",
    "                    np.unique(sample_preds),                        \n",
    "                    key=lambda label : sum(sample_preds == label))\n",
    "                for sample_preds in pred_T]                         # For each sample in predictions (sample_preds is a list of all predictions from estimators for one sample)\n",
    "        \n",
    "        return vote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243ee86-bbf5-4bcd-834c-628ea296d894",
   "metadata": {},
   "source": [
    "## Data reading and evaluation\n",
    "\n",
    "There is no need to update the following cell, it just declare functions to read the dataset, evaluate and run the experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558627f-9553-4d3f-b9ec-44eef153412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_dataset(dataset_path='electricity2.csv'):\n",
    "    _data = pd.read_csv(dataset_path)\n",
    "    # class label must be the last column\n",
    "    X = _data.iloc[:, :-1]\n",
    "    y = _data.iloc[:, -1]\n",
    "    return (X, y)\n",
    "\n",
    "# train-test split and return accuracy\n",
    "def evaluate_classifier(classifier, X, y, test_size=0.3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# perform experiments in one dataset for several classifiers\n",
    "def run_experiments(classifiers, show_oob=True):\n",
    "    (X_electricity, y_electricity) = load_dataset(dataset_path='electricity2.csv')\n",
    "    \n",
    "    results = []\n",
    "    datasets = {\n",
    "        'Electricity': (X_electricity, y_electricity)\n",
    "    }\n",
    "    \n",
    "    for dataset_name, (X, y) in datasets.items():\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            print(f\"running {clf_name}\")\n",
    "            accuracy, _, _, _, _ = evaluate_classifier(clf, X, y)\n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Classifier': clf_name,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "            if isinstance(clf, RandomPatches) and show_oob:\n",
    "                for i, (subspace, oob_set_size, oob_accuracy) in enumerate(zip(clf.subspaces, clf.oob_sets_size, clf.oob_scores)):\n",
    "                    print(f\"Base Learner {i+1} Subspace (features): {subspace} OOB Instances: {oob_set_size} OOB Accuracy: {oob_accuracy:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69936b8-788b-4ddb-ba55-fec192eb9abc",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Modify this part of the code to add more experiments as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233068d-14ff-40fb-9d2c-f7ecf58b112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Run the experiments and display results\n",
    "classifiers = {\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'Bagging': BaggingClassifier(n_estimators=20),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "        'XGBoost': XGBClassifier(eval_metric='logloss'),\n",
    "        'RandomPatches(4,10)': RandomPatches(max_features=4, n_estimators=10)\n",
    "    }\n",
    "\n",
    "results_df = run_experiments(classifiers, show_oob=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df412e56",
   "metadata": {},
   "source": [
    "### Impact of Ensemble Size and Feature Subset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec7b3b-7990-4383-89c0-43a62b8c1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of ensemble size (keeping max_features=4 constant)\n",
    "ensemble_sizes_list = [5, 10, 50]  \n",
    "ensemble_sizes = {\n",
    "    f'RandomPatches(4,{size})' : RandomPatches(n_estimators=size)\n",
    "    for size in ensemble_sizes_list\n",
    "}\n",
    "\n",
    "# Impact of feature subset size (keeping n_estimators=10 constant)\n",
    "feature_subset_sizes_list = [2, 4, 6, 8, 11] \n",
    "feature_subset_sizes = {\n",
    "    f'RandomPatches({size},10)' : RandomPatches(max_features=size)\n",
    "    for size in feature_subset_sizes_list\n",
    "}\n",
    "\n",
    "results_ensemble = run_experiments(ensemble_sizes, show_oob=True)\n",
    "results_features = run_experiments(feature_subset_sizes, show_oob=True)\n",
    "\n",
    "# Plot line graphs for each experiment\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ensemble_accuracies = results_ensemble['Accuracy'].values\n",
    "feature_accuracies = results_features['Accuracy'].values\n",
    "ax[0].plot(ensemble_sizes_list, ensemble_accuracies, marker='o', linewidth=2, markersize=8)\n",
    "ax[0].set_xlabel('Number of Estimators')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_title('Impact of Ensemble Size on RandomPatches Performance\\n(max_features=4)')\n",
    "ax[0].set_xticks(ensemble_sizes_list)\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "ax[1].plot(feature_subset_sizes_list, feature_accuracies, marker='s', linewidth=2, markersize=8, color='orange')\n",
    "ax[1].set_xlabel('Number of Features')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Impact of Feature Subset Size on RandomPatches Performance\\n(n_estimators=10)')\n",
    "ax[1].set_xticks(feature_subset_sizes_list)\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the results tables\n",
    "print(\"\\nEnsemble Size Experiment Results\")\n",
    "display(results_ensemble)\n",
    "print(\"\\nFeature Subset Size Experiment Results\")\n",
    "display(results_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18231e3e",
   "metadata": {},
   "source": [
    "### Custom Voting Scheme (Weighted Majority) vs. Majority Voting Scheme\n",
    "(+ Comparison of OOB Accuracies vs. Ensemble Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_schemes_list = ['majority', 'weighted_majority']\n",
    "voting_schemes = {\n",
    "    f'RandomPatches(4,10,{voting})' : RandomPatches(custom_voting=voting)\n",
    "    for voting in voting_schemes_list\n",
    "}\n",
    "\n",
    "results_voting = run_experiments(voting_schemes, show_oob=True)\n",
    "display(results_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ab157",
   "metadata": {},
   "source": [
    "### Other Improvements: Probabilistic Voting Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f870b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running RandomPatches(4,10,majority)\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n",
      "running RandomPatches(4,10,weighted_majority)\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n",
      "running RandomPatches(4,10,weighted_majority)\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n",
      "running RandomPatches(4,10,probabilistic)\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n",
      "running RandomPatches(4,10,probabilistic)\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n",
      "Base Learner 1 Subspace (features): [10  8  4  2] OOB Instances: 11684 OOB Accuracy: 73.6392\n",
      "Base Learner 2 Subspace (features): [6 9 2 5] OOB Instances: 11685 OOB Accuracy: 70.0471\n",
      "Base Learner 3 Subspace (features): [ 9  7 10  5] OOB Instances: 11645 OOB Accuracy: 52.7351\n",
      "Base Learner 4 Subspace (features): [8 1 9 3] OOB Instances: 11626 OOB Accuracy: 53.9136\n",
      "Base Learner 5 Subspace (features): [ 2 10  9  6] OOB Instances: 11698 OOB Accuracy: 70.7813\n",
      "Base Learner 6 Subspace (features): [9 8 7 0] OOB Instances: 11643 OOB Accuracy: 58.6361\n",
      "Base Learner 7 Subspace (features): [9 5 3 7] OOB Instances: 11664 OOB Accuracy: 51.4832\n",
      "Base Learner 8 Subspace (features): [5 7 1 6] OOB Instances: 11652 OOB Accuracy: 58.9513\n",
      "Base Learner 9 Subspace (features): [6 2 8 7] OOB Instances: 11692 OOB Accuracy: 71.2196\n",
      "Base Learner 10 Subspace (features): [ 0  2 10  5] OOB Instances: 11586 OOB Accuracy: 72.6049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>RandomPatches(4,10,majority)</td>\n",
       "      <td>0.745476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>RandomPatches(4,10,weighted_majority)</td>\n",
       "      <td>0.764014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>RandomPatches(4,10,probabilistic)</td>\n",
       "      <td>0.643225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset                             Classifier  Accuracy\n",
       "0  Electricity           RandomPatches(4,10,majority)  0.745476\n",
       "1  Electricity  RandomPatches(4,10,weighted_majority)  0.764014\n",
       "2  Electricity      RandomPatches(4,10,probabilistic)  0.643225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "voting_schemes_list = ['majority', 'weighted_majority', 'probabilistic']\n",
    "voting_schemes = {\n",
    "    f'RandomPatches(4,10,{voting})' : RandomPatches(custom_voting=voting)\n",
    "    for voting in voting_schemes_list\n",
    "}\n",
    "\n",
    "results_voting = run_experiments(voting_schemes, show_oob=True)\n",
    "display(results_voting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
